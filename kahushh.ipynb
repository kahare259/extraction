{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libraries to used in the project\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset repo for providing data\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to be values between 0 and 1 doining transformation\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Print the shape of the data\n",
    "print(\"Train Images Shape:\", train_images.shape)\n",
    "print(\"Train Labels Shape:\", train_labels.shape)\n",
    "print(\"Test Images Shape:\", test_images.shape)\n",
    "print(\"Test Labels Shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator instance with desired augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,      # Rotate images by a random degree between -10 and 10\n",
    "    width_shift_range=0.1,  # Shift images horizontally by a fraction of total width\n",
    "    height_shift_range=0.1, # Shift images vertically by a fraction of total height\n",
    "    shear_range=0.2,        # Shear intensity (angle in counter-clockwise direction)\n",
    "    zoom_range=0.2,         # Zoom images by a random factor between 0.8 and 1.2\n",
    "    horizontal_flip=True,   # Flip images horizontally\n",
    "    vertical_flip=False     # Do not flip images vertically\n",
    "\n",
    "    #Playing arround with images and to check them\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reshape the data to 4D tensor (batch_size, height, width, channels) for ImageDataGenerator\n",
    "train_images_reshaped = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "\n",
    "# Fit the ImageDataGenerator on the training data\n",
    "datagen.fit(train_images_reshaped)\n",
    "\n",
    "# Create an iterator to generate augmented images\n",
    "augmented_images_iterator = datagen.flow(train_images_reshaped, train_labels, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    # Use the correct method to get the next batch\n",
    "    batch = next(augmented_images_iterator)  # Use next() instead of .next()\n",
    "    image = batch[0][0].reshape(28, 28)  # Assuming the image is in the first position of the batch\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images for easier analysis\n",
    "train_images_flat = train_images.reshape(train_images.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Histogram of Pixel Intensities\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(train_images_flat[0], bins=50, color='skyblue', alpha=0.7)\n",
    "plt.title('Histogram of Pixel Intensities')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Scatter Plot of Pixel Intensities\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(train_images_flat[0], train_images_flat[1], alpha=0.5)\n",
    "plt.title('Scatter Plot of Pixel Intensities')\n",
    "plt.xlabel('Pixel Intensity (Image 1)')\n",
    "plt.ylabel('Pixel Intensity (Image 2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot of Pixel Intensities\n",
    "sns.pairplot(pd.DataFrame(train_images_flat[:, :5]))\n",
    "plt.suptitle('Pairplot of Pixel Intensities', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of Pixel Intensities corellation in the data\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(train_images_flat[:10], cmap='viridis')\n",
    "plt.title('Heatmap of Pixel Intensities')\n",
    "plt.xlabel('Pixel')\n",
    "plt.ylabel('Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie Chart of Class Label Distribution\n",
    "class_counts = dict(Counter(train_labels))\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(class_counts.values(), labels=class_counts.keys(), autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Class Label Distribution')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and testing sets  test_size=0.2 20 % for test and 80 % for train\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"Training Images Shape:\", X_train.shape)\n",
    "print(\"Training Labels Shape:\", y_train.shape)\n",
    "print(\"Testing Images Shape:\", X_test.shape)\n",
    "print(\"Testing Labels Shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(28, 28, 1)),  # Define input shape explicitly here\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the EarlyStopping callback to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train, epochs=3, batch_size=32,\n",
    "                    validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Perform predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=range(10), yticklabels=range(10))\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install specific versions of the required libraries\n",
    "!pip -q install langchain==0.3.19\n",
    "!pip -q install langchain-google-genai==2.0.10\n",
    "!pip -q install google-generativeai==0.8.0\n",
    "!pip -q install google-ai-generativelanguage==0.6.2  # Downgraded to match google-generativeai 0.8.0\n",
    "!pip -q install docarray==0.40.0\n",
    "!pip -q install langchain_experimental\n",
    "!pip -q install langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check The model specification\n",
    "!pip show langchain langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setting up the Auth\n",
    "import os\n",
    "import google.generativeai as genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY=userdata.get('GOOGLE_API_KEY')\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.display import Image\n",
    "\n",
    "image_url = \"https://templates.invoicehome.com/receipt-template-us-neat-750px.png\"\n",
    "content = requests.get(image_url).content\n",
    "Image(content,width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro-vision\")\n",
    "\n",
    "# example\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"What is the image showing ??\",\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": image_url\n",
    "         },\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm.invoke([message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q -O - ipv4.icanhazip.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run app.py & npx localtunnel --port 8501"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
